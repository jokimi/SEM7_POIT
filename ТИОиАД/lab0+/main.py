import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (classification_report, confusion_matrix,
                             accuracy_score, precision_score, recall_score, f1_score,
                             roc_curve, auc)
from sklearn.preprocessing import label_binarize
import warnings

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

print("=" * 100)
df = pd.read_csv('PersonalityTypes.csv')

missing_values = df.isnull().sum()
print(f"\n–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:\n{missing_values[missing_values > 0]}")

categorical_cols = df.select_dtypes(include=['object']).columns
print("\n–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö:")
for col in categorical_cols:
    print(f"{col}: {df[col].unique()}")

# 2. –ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
plt.figure(figsize=(14, 6))
personality_counts = df['Personality'].value_counts()
colors = plt.cm.Set3(np.linspace(0, 1, len(personality_counts)))

bars = plt.bar(range(len(personality_counts)), personality_counts.values, color=colors)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏', fontsize=16, fontweight='bold')
plt.xlabel('–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏', fontsize=12)
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π', fontsize=12)
plt.xticks(range(len(personality_counts)), personality_counts.index, rotation=45, ha='right')

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2., height + 0.5,
             f'{int(height)}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

numeric_cols = df.select_dtypes(include=[np.number]).columns
plt.figure(figsize=(12, 10))
correlation_matrix = df[numeric_cols].corr()

mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r',
            center=0, square=True, fmt='.2f', cbar_kws={"shrink": .8})
plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

print("\n" + "=" * 100 + "\n")

target_column = 'Personality'
print(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target_column}")
X = df.drop(columns=[target_column])
y = df[target_column]

categorical_cols = X.select_dtypes(include=['object']).columns
label_encoders = {}
if len(categorical_cols) > 0:
    print(f"–ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {list(categorical_cols)}")
    for col in categorical_cols:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        label_encoders[col] = le

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
le_target = LabelEncoder()
y_encoded = le_target.fit_transform(y)

print(f"–ö–ª–∞—Å—Å—ã —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {dict(enumerate(le_target.classes_))}")

# –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤—ã—Ö ROC –∫—Ä–∏–≤—ã—Ö
y_bin = label_binarize(y_encoded, classes=np.unique(y_encoded))
n_classes = y_bin.shape[1]

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# –¢–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª—è–µ–º –±–∏–Ω–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
_, X_test_bin, _, y_test_bin = train_test_split(
    X, y_bin, test_size=0.2, random_state=42, stratify=y_encoded
)

print(f"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} samples")
print(f"   –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} samples")
print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")
print(f"   –ö–ª–∞—Å—Å–æ–≤: {n_classes}")

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è KNN)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_test_bin_scaled = scaler.transform(X_test_bin)

# 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π

print("\n" + "=" * 100 + "\n")

models = {
    'Random Forest': RandomForestClassifier(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        class_weight='balanced'
    ),
    'K-Nearest Neighbors': KNeighborsClassifier(
        n_neighbors=15,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        weights='distance',  # –ë–ª–∏–∑–∫–∏–µ —Å–æ—Å–µ–¥–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å
        algorithm='auto',
        p=2,  # –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        metric='minkowski'
    ),
    'Logistic Regression': LogisticRegression(
        C=1.0,
        penalty='l2',
        max_iter=1000,
        random_state=42,
        class_weight='balanced',
        solver='lbfgs',
        multi_class='multinomial'
    )
}

results = {}

for name, model in models.items():
    print(f"–û–±—É—á–µ–Ω–∏–µ {name}:")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model.fit(X_train_scaled, y_train)

    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=3, scoring='accuracy')

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = model.predict(X_test_scaled)
    y_prob = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None

    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

    results[name] = {
        'model': model,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'y_pred': y_pred,
        'y_prob': y_prob
    }

    print(f"   Test Accuracy: {accuracy:.3f}")
    print(f"   CV Accuracy: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")

# 5. –û—Ü–µ–Ω–∫–∞ –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

print("\n" + "=" * 60)

metrics_data = []
for name, result in results.items():
    metrics_data.append({
        'Model': name,
        'Test Accuracy': result['accuracy'],
        'CV Accuracy': result['cv_mean'],
        'F1-Score': result['f1']
    })

metrics_df = pd.DataFrame(metrics_data).sort_values('Test Accuracy', ascending=False)

# –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
plt.figure(figsize=(14, 8))
x_pos = np.arange(len(metrics_df))
width = 0.35

plt.bar(x_pos - width / 2, metrics_df['Test Accuracy'], width, label='Test Accuracy', alpha=0.8)
plt.bar(x_pos + width / 2, metrics_df['CV Accuracy'], width, label='CV Accuracy', alpha=0.8)

plt.xlabel('–ú–æ–¥–µ–ª–∏', fontweight='bold')
plt.ylabel('Accuracy', fontweight='bold')
plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π', fontsize=16, fontweight='bold')
plt.xticks(x_pos, metrics_df['Model'], rotation=45, ha='right')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(metrics_df.to_string(index=False))

# –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-2 –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è ROC –∫—Ä–∏–≤—ã—Ö
top_models = metrics_df.head(2)['Model'].tolist()

for model_name in top_models:
    print(f"\n–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ROC –∫—Ä–∏–≤—ã—Ö –¥–ª—è {model_name}:")

    model = results[model_name]['model']
    y_prob = model.predict_proba(X_test_bin_scaled)

    # –í—ã—á–∏—Å–ª—è–µ–º ROC –∫—Ä–∏–≤—ã–µ –∏ AUC –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # –í—ã—á–∏—Å–ª—è–µ–º micro-average ROC curve –∏ ROC area
    fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_prob.ravel())
    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ROC –∫—Ä–∏–≤—ã—Ö –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
    plt.figure(figsize=(12, 10))

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 6 –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    classes_to_show = min(6, n_classes)
    colors = plt.cm.Set1(np.linspace(0, 1, classes_to_show))

    for i, color in zip(range(classes_to_show), colors):
        plt.plot(fpr[i], tpr[i], color=color, lw=2,
                 label='ROC –∫–ª–∞—Å—Å–∞ {0} ({1:0.2f})'
                       ''.format(le_target.classes_[i], roc_auc[i]))

    # Micro-average ROC curve
    plt.plot(fpr["micro"], tpr["micro"],
             label='Micro-average ROC ({0:0.2f})'
                   ''.format(roc_auc["micro"]),
             color='deeppink', linestyle=':', linewidth=4)

    # –°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (0.50)')

    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate', fontweight='bold')
    plt.ylabel('True Positive Rate', fontweight='bold')
    plt.title(f'üìà ROC –∫—Ä–∏–≤—ã–µ –¥–ª—è {model_name}\n(–ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {classes_to_show} –∫–ª–∞—Å—Å–æ–≤)',
              fontsize=16, fontweight='bold')
    plt.legend(loc="lower right", bbox_to_anchor=(1.6, 0))
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    # –í—ã–≤–æ–¥–∏–º AUC –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
    print(f"AUC –¥–ª—è {model_name}:")
    for i in range(n_classes):
        print(f"   {le_target.classes_[i]}: {roc_auc[i]:.3f}")
    print(f"   Micro-average: {roc_auc['micro']:.3f}")

# –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –¥–ª—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
fig, axes = plt.subplots(1, 2, figsize=(16, 7))
for i, model_name in enumerate(top_models):
    result = results[model_name]
    cm = confusion_matrix(y_test, result['y_pred'])

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                cbar_kws={'shrink': 0.8})
    axes[i].set_title(f'üìã {model_name}\nAccuracy: {result["accuracy"]:.3f}', fontweight='bold')
    axes[i].set_xlabel('Predicted', fontweight='bold')
    axes[i].set_ylabel('Actual', fontweight='bold')

plt.suptitle('–ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π', fontsize=16, fontweight='bold', y=0.98)
plt.tight_layout()
plt.show()

# –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
best_model_name = metrics_df.iloc[0]['Model']
best_model = results[best_model_name]['model']

print(f"\n–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
print(f"   Test Accuracy: {results[best_model_name]['accuracy']:.3f}")
print(f"   F1-Score: {results[best_model_name]['f1']:.3f}")
print(f"   CV Accuracy: {results[best_model_name]['cv_mean']:.3f} ¬± {results[best_model_name]['cv_std']:.3f}")

if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)

    plt.figure(figsize=(12, 8))
    bars = plt.barh(feature_importance['feature'][:10],
                    feature_importance['importance'][:10])
    plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞', fontweight='bold')
    plt.title('–¢–æ–ø —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=16, fontweight='bold')
    plt.gca().invert_yaxis()
    plt.grid(True, alpha=0.3)

    for bar in bars:
        width = bar.get_width()
        plt.text(width + 0.001, bar.get_y() + bar.get_height() / 2.,
                 f'{width:.3f}', ha='left', va='center')

    plt.tight_layout()
    plt.show()

    print("\n–¢–æ–ø-5 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, row in feature_importance.head().iterrows():
        print(f"   {i + 1}. {row['feature']}: {row['importance']:.3f}")