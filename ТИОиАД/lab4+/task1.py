# –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º –≤—ã—á–∏—Ç–∞–Ω–∏—è —Ñ–æ–Ω–∞

import cv2
import numpy as np
import datetime

def background_subtraction_detection(video_source=0):
    cap = cv2.VideoCapture(video_source)
    if not cap.isOpened():
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ –∏—Å—Ç–æ—á–Ω–∏–∫ {video_source}")
        return

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ñ–æ–Ω–∞
    backSub = cv2.createBackgroundSubtractorKNN(
        history=500,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ñ–æ–Ω–∞
        dist2Threshold=400,  # –ü–æ—Ä–æ–≥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
        detectShadows=True  # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç–µ–Ω–µ–π
    )

    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞ –¥–≤–∏–∂–µ–Ω–∏—è
    motion_detected = False
    motion_start_time = None
    motion_counter = 0
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            print("–í–∏–¥–µ–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å –∏–ª–∏ –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è")
            break

        frame_count += 1

        if width > 800:
            frame = cv2.resize(frame, (640, 480))
            height, width = frame.shape[:2]

        # –í—ã—á–∏—Ç–∞–Ω–∏–µ —Ñ–æ–Ω–∞ –∏ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è
        fgMask = backSub.apply(frame)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_OPEN, kernel)
        fgMask = cv2.morphologyEx(fgMask, cv2.MORPH_CLOSE, kernel)

        contours, _ = cv2.findContours(fgMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã –ø–æ –ø–ª–æ—â–∞–¥–∏
        min_area = 1000  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]

        # Bounding box –≤–æ–∫—Ä—É–≥ –¥–≤–∏–∂—É—â–∏—Ö—Å—è –æ–±—ä–µ–∫—Ç–æ–≤
        motion_detected_current = len(large_contours) > 0

        for contour in large_contours:
            x, y, w, h = cv2.boundingRect(contour)
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.putText(frame, "MOVING OBJECT", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

            # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                cv2.circle(frame, (cx, cy), 5, (255, 0, 0), -1)

        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è
        if motion_detected_current and not motion_detected:
            motion_detected = True
            motion_start_time = datetime.datetime.now()
            motion_counter += 1
            print(f"üî¥ –û–ë–ù–ê–†–£–ñ–ï–ù–û –î–í–ò–ñ–ï–ù–ò–ï!")
        elif not motion_detected_current and motion_detected:
            motion_detected = False
            end_time = datetime.datetime.now()
            duration = (end_time - motion_start_time).total_seconds()
            print(f"üü¢ –î–í–ò–ñ–ï–ù–ò–ï –ü–†–ï–ö–†–ê–¢–ò–õ–û–°–¨. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f} —Å–µ–∫")

        status = "MOVEMENT DETECTED" if motion_detected else "NO MOVEMENT"
        color = (0, 0, 255) if motion_detected else (0, 255, 0)

        info_panel = np.zeros((100, frame.shape[1], 3), dtype=np.uint8)

        cv2.putText(info_panel, f"Status: {status}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(info_panel, f"Motion Count: {motion_counter}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(info_panel, f"Frame: {frame_count}", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        display_frame = np.vstack([frame, info_panel])

        cv2.putText(display_frame, "Press 'q' to quit, 'p' to pause",
                    (10, frame.shape[0] + 80), cv2.FONT_HERSHEY_SIMPLEX,
                    0.5, (255, 255, 255), 1)

        cv2.imshow('Motion Detection - Original Video', display_frame)
        cv2.imshow('Motion Detection - Foreground Mask', fgMask)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('p'):
            print("–ü–ê–£–ó–ê. –ù–∞–∂–º–∏—Ç–µ –ª—é–±—É—é –∫–ª–∞–≤–∏—à—É –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            cv2.waitKey(0)

    cap.release()
    cv2.destroyAllWindows()

    print(f"\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {frame_count}")
    print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π –¥–≤–∏–∂–µ–Ω–∏—è: {motion_counter}")

if __name__ == "__main__":
    background_subtraction_detection()